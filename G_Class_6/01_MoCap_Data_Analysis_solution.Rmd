---
date: "2023-11-06"
title: "Class G, Mocap data"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# to make things easy, we will use pacman. Please install it if you don't have it already
# with install.packages("pacman")

# packages to load
pacman::p_load(
  "XML",
  "tidyverse",
  "fs",
  "assertthat",
  "stringi",
  "dtw",
  "RTransferEntropy",
  "signal",
  "conflicted",
  "Rcpp",
  "future"
)

# make sure we are in the G_Class_6 directory
wd <- getwd()
if (basename(wd) != "G_Class_6") {
  setwd("./G_Class_6")
}
dev.off()
# set the directory for the data
data_dir <- path_home() %>% 
  path("OneDrive - Aarhus universitet", "PercActMotionCapture", "labeled_data", "tsvs")

# set your study group
group_number <- 0

# The available conditions and their start and end frame indices
# to use the whole file, just set the value for the condition to c(NA, NA)
conditions <- list(
  jointlead = c(100, 10000),
  followlead = c(100, 10000),
  leadfollow = c(100, 10000),
  custom = c(100, 10000)
)



```

```{r helper_functions, include=FALSE}
# adapted from
# https://github.com/zeyus/QTM_Bela_Sonification/blob/main/scripts/step_01_import_raw_data.R

process_qtm_tsv <- function(
    data_file,
    condition_regex = "group[0-9]+_([^_\\.]+).*",
    null_value = "NA"
  ) {
  "This function processes a QTM TSV file and reads it into a dataframe.

  You will get both the trajectory data (dataframe) as well as metadata.

  Args:
    data_file (str): The path to the QTM TSV file.
    condition_regex (str): A regex to extract the condition from the file name.
    null_value (str): The value in the files that represents a missing measurement.

  Returns:
    A list with two elements:
      - data: The trajectory data as a dataframe.
      - metadata: A list with the metadata.
          The metadata contains the following elements:
            - condition: The condition of the data.
            - frequency: The frequency (Hz) of the data.
            - marker_count: The number of markers.
            - frame_count: The number of frames.
            - marker_names: The names of the markers.
  "

  message(paste("Processing", data_file))

  # get the condition
  cond <- stri_match_last_regex(data_file, condition_regex)[2]
  # make condition lowercase
  cond <- tolower(cond)
  message(paste("Condition:", cond))

  # read in the data
  dat <- readLines(data_file)

  # now get other relevant metadata
  # get frequency
  freq <- stri_match_first_regex(dat, "^FREQUENCY.*")
  freq <- freq[!is.na(freq)]

  # get marker count
  marker_count <- stri_extract_first_regex(dat, "^NO_OF_MARKERS.*")
  marker_count <- marker_count[!is.na(marker_count)]
  marker_count_value <- as.integer(stri_split_fixed(marker_count, "\t")[[1]][2])

  # get frame count
  frame_count <- stri_extract_first_regex(dat, "^NO_OF_FRAMES.*")
  frame_count <- frame_count[!is.na(frame_count)]
  frame_count_value <- as.integer(stri_split_fixed(frame_count, "\t")[[1]][2])

  # get marker names
  marker_names <- stri_extract_first_regex(dat, "^MARKER_NAMES.*")
  marker_names <- marker_names[!is.na(marker_names)]
  marker_names_values <- stri_split_fixed(
    marker_names,
    "\t"
  )[[1]][1:marker_count_value + 1]
  message("File information:")
  message(paste(freq, "Hz", "frequency"))
  message(paste(marker_count_value, "markers"))
  message(paste(frame_count_value, "frames"))

  # now just keep the tracking information
  dat <- stri_extract_first_regex(dat, "^[0-9]+\t.*")
  dat <- dat[!is.na(dat)]

  # now ensure the number of frames is correct
  # this is the number of lines in the data
  assertthat::assert_that(
    length(dat) == frame_count_value,
    msg = paste(
      "Number of frames is not correct, found:",
      length(dat),
      "expected:",
      frame_count_value)
  )

  # ensure the number of markers is correct
  # this is 3 columns per marker, plus index and time
  num_found_markers <- length(stri_split_fixed(dat[[1]], "\t")[[1]])
  assertthat::assert_that(
    num_found_markers == marker_count_value * 3 + 2,
    msg = paste(
      "Number of markers is not correct, found:",
      num_found_markers,
      "expected:",
      marker_count_value * 3 + 2)
  )

  message(paste("File has", length(dat), "frames"))
  message(paste("File has", marker_count_value, "markers"))

  message("Creating data frame...")

  col_names <- c(
    "index",
    "elapsed_time",
    paste0(
      rep(marker_names_values, each = 3),
      c("_x", "_y", "_z")
    )
  )


  # now we need to create a data frame
  
  # split each line by tab
  dat <- stri_split_fixed(dat, "\t", simplify = TRUE)
  # set the column names
  colnames(dat) <- col_names
  # and then convert to a data frame
  dat <- as_tibble(dat)
  # now we need to replace the null values with NA
  dat[dat == null_value] <- NA
  # and convert to numeric
  dat <- mutate_all(dat, as.numeric)

  metadata <- list(
    condition = cond,
    frequency = freq,
    marker_count = marker_count,
    frame_count = frame_count,
    marker_names = marker_names
  )

  # return the data and metadata
  return(list(data = dat, metadata = metadata))

}



gap_fill_linear <- function(x) {
  "This function does a linear gap fill for a vector.

  Only columns with at least 2 non-NA values will be gap filled.

  Args:
    x (vector): The vector to gap fill.

  Returns:
    The gap filled vector.
  "
  # get the indices of the NA values
  na_indices <- which(is.na(x))
  # get the indices of the non-NA values
  non_na_indices <- which(!is.na(x))

  if (length(na_indices) == 0) {
    # if there are no NA values, just return the vector
    return(x)
  }

  if (length(non_na_indices) < 2) {
    # if there are less than 2 non-NA values, we can't do a linear interpolation
    return(x)
  }
  # get the values of the non-NA indices
  non_na_values <- x[non_na_indices]
  # get the values of the NA indices
  na_values <- x[na_indices]
  # now we can do a linear interpolation
  na_values <- approx(
    x = non_na_indices,
    y = non_na_values,
    xout = na_indices,
    method = "linear"
  )$y
  # now we can replace the NA values with the interpolated values
  x[na_indices] <- na_values
  # and return the vector
  return(x)
}

```


```{r 'Load Trajectory Labels'}
# load the labels from the XML file

# load the XML file
xmlfile <- xmlParse("./resources/PerAct23_LabelList.xml")

# get the labels, which are in the following format:
# <QTM_Label_List_Ver_1.00>
#     <Trajectories>
#         <Trajectory>
#             <Name>A_head_top</Name>
#             <Color R="0" G="147" B="0"/>
#         </Trajectory>
#     </Trajectories>
# </QTM_Label_List_Ver_1.00>

# get the trajectory names
traj_names <- xpathSApply(xmlfile, "//Trajectory/Name", xmlValue)

# get the trajectory colors
traj_colors <- xpathSApply(xmlfile, "//Trajectory/Color", xmlAttrs)

# convert the colors to hex
traj_colors <- rgb(
  as.numeric(traj_colors[1,]),
  as.numeric(traj_colors[2,]),
  as.numeric(traj_colors[3,]),
  alpha = 255,
  maxColorValue = 255
)


# combine the names and colors into a data frame
traj_labels <- data.frame(
  traj_names,
  traj_colors,
  stringsAsFactors = FALSE
)

rm(xmlfile, traj_names, traj_colors)

```

```{r 'Load Trajectory Data'}

# load the trajectory data, we want all TSVs with the group number in the name

# get the files
traj_files <- fs::dir_ls(data_dir, regexp = paste0("group", group_number, "_.*\\.tsv$"))

# load the data
traj_data <- lapply(traj_files, process_qtm_tsv)


# now we need to combine the data into a single data frame

# first we need to add the condition and group to each data frame
traj_data <- lapply(traj_data, function(x) {
  x$data$condition <- x$metadata$condition
  x$data$group <- paste0("group", group_number)
  return(x)
})

# now we can combine the data
traj_data <- do.call(bind_rows, lapply(traj_data, `[[`, "data"))

# make the condition and group factors
traj_data$condition <- factor(traj_data$condition)
traj_data$group <- factor(traj_data$group)

# take a look at the data
head(traj_data)

# let's also make sure that all of the marker names are the same
# we can do this by getting the unique marker names
marker_names <- unique(traj_data %>% select(contains("_x")) %>% names() %>% stri_replace_last_regex("_x", ""))

# now we can check that all of the marker names are the same
assertthat::assert_that(
  all(marker_names == traj_labels$traj_names),
  msg = "Not all marker names are the same"
)

# let's make the data long format so we can easily group by subject or marker
traj_data <- traj_data %>% 
  pivot_longer(
    cols = contains("_x") | contains("_y") | contains("_z"),
    cols_vary = "slowest",
    names_to = "marker",
    values_to = "value"
  ) %>%
  mutate(
    subject = stri_replace_first_regex(marker, "^([AB])_.*", "$1"),
    axis = stri_extract_last_regex(marker, "[xyz]$"),
    marker = stri_replace_first_regex(marker, "^[AB]_([a-zA-Z_]+)_[xyz]$", "$1")
  )

# move axes to columns
traj_data <- traj_data %>% 
  pivot_wider(
    names_from = axis,
    values_from = value
  )
traj_data$marker <- factor(traj_data$marker, levels = marker_names)

```

```{r 'Crop trajectory data'}

# We want to crop the data for each condition
# let's get all the recorded conditions
recorded_conditions <- unique(traj_data$condition)
for (cond in recorded_conditions) {
  # get the start and end frame for the condition
  start_frame <- conditions[[cond]][1]
  if (is.na(start_frame)) start_frame <- 1
  end_frame <- conditions[[cond]][2]
  if (is.na(end_frame)) end_frame <- max(traj_data[traj_data$condition == cond, "index"])
  # crop the data
  traj_data <- traj_data %>% 
    dplyr::filter(condition == cond & index >= start_frame & index <= end_frame | condition != cond)
}

# select min and max indices by condition
traj_data %>% 
  group_by(condition) %>% 
  summarise(
    min_index = min(index),
    max_index = max(index))

# report observations per condition
traj_data %>% 
  group_by(condition, subject, marker) %>% 
  summarise(
    n_obs = n()
  ) %>%
  print(n = 100)

```


```{r 'Check for large jumps in trajectory data'}
# we want to check for large jumps in the data
# this indicates potential label errors

# we will do this by calculating the distance between each marker for each time point
# of course, by condition



# calculate the euclidean distance between each marker (using x, y, z)
# we will do this by condition, subject, marker and axis
marker_distances <- traj_data %>% 
  group_by(condition, subject, marker) %>%
  arrange(index) %>%
  mutate(
    diff_x = x - lag(x, 1),
    diff_y = y - lag(y, 1),
    diff_z = z - lag(z, 1)
  )
  

# now we can calculate the euclidean distance per maker
marker_distances <- marker_distances %>% 
  mutate(
    euclidean_distance = sqrt(diff_x^2 + diff_y^2 + diff_z^2)
  )

# now we can plot the series for each marker, and see if anything stands out
marker_distances %>% 
  ggplot(aes(x = index, y = euclidean_distance, color = marker)) +
  geom_line(linewidth=1.25) +
  theme_minimal() +
  facet_wrap(c(~condition, ~subject)) +
  labs(
    x = "Index",
    y = "Euclidean distance",
    title = "Euclidean distance from previous frame by marker"
  )


```

```{r 'Get informatnion about NAs'}	

# get NAs counts
# by condition, marker, subject and axis
nas_cond_marker <- traj_data %>%
  group_by(condition, subject, marker) %>%
  summarise_at(
    vars(x, y, z),
    ~ sum(is.na(.))
  )


# plot to check if it is acceptable
nas_cond_marker %>% 
  ggplot(aes(x = marker, y = x, fill=marker, group=subject)) +
  geom_col(
    show.legend = FALSE
  ) +
  coord_flip() +
  theme_minimal() +
  facet_wrap(c(~subject, ~condition)) +
  labs(
    x = "Marker",
    y = "NA count",
    title = "NA count by marker"
  )

# Now we can get the longest sequence of NAs for each marker
longest_na_seq <- traj_data %>% 
  group_by(condition, subject, marker) %>%
  summarise_at(
    vars(x, y, z),
    ~ max(rle(is.na(.))$lengths)
  )

# plot to check if it is acceptable
longest_na_seq %>% 
  ggplot(aes(x = marker, y = x, fill=marker, group=subject)) +
  geom_col(
    show.legend = FALSE
  ) +
  coord_flip() +
  theme_minimal() +
  facet_wrap(c(~subject, ~condition)) +
  labs(
    x = "Marker",
    y = "Longest NA sequence",
    title = "Longest NA sequence by marker"
  )

```

```{r 'Choose markers of interest'}
# we want to choose the markers of interest
# we will choose the following markers:
# - {A,B}_head_top
# - {A,B}_hand_right
# you may of course choose different markers, or if those ones were
# particularly bad, you should select others

# get the markers of interest
markers_of_interest <- c(
  "hand_right"
)

# now we can select the markers of interest
selected_traj_data <- traj_data %>% 
  dplyr::filter(marker %in% markers_of_interest)

```

```{r 'Gap fill trajectory data'}
# we are only going to do a linear gap fill, it's not elegant, but it works
# we will do this for each marker x, y, and z

# choose a single marker for plotting purposes only
sel_idx = 1

# plot a single marker's x, y, and z values before and after gap filling
selected_traj_data %>% 
  ggplot(aes(x = elapsed_time, y = x, color = subject)) +
  geom_line() +
  theme_minimal() +
  facet_wrap(c(~condition)) +
  labs(
    x = "Elapsed time",
    y = "Marker X position",
    title = "Marker X position before gap filling"
  )

# now we can apply our linear gap fill function to each column, by condition
selected_traj_data <- selected_traj_data %>% 
  group_by(condition, subject, marker) %>% 
  mutate_at(
    vars(x, y, z),
    ~ gap_fill_linear(.)
  )

# plot a single marker's x, y, and z after gap filling
selected_traj_data %>% 
  ggplot(aes(x = elapsed_time, y = x, color = subject)) +
  geom_line() +
  theme_minimal() +
  facet_wrap(c(~condition)) +
  labs(
    x = "Elapsed time",
    y = "Marker X position",
    title = "Marker X position after gap filling"
  )
```


```{r 'Cross correlation analysis'}
# we want to do a cross correlation analysis
# we know there are always two subjects, and the
# marker labels start with the subject (A or B)
# we want to cross correlate between the same marker for
# subject A and subject B

# set the maximum lag in samples. e.g. 300 samples is 1 second
max_lag <- 900 # correlate with +/- 3 seconds

# define an empty list to store the results
xcor_results <- list()
for (marker in markers_of_interest) {
  # get the data for the marker
  marker_data <- selected_traj_data %>% 
    dplyr::filter(marker == marker)
  # get the unique conditions
  conds <- unique(marker_data$condition)
  # now we can do the cross correlation analysis
  for (cond in conds) {
    # get the data for the condition
    cond_data <- marker_data %>% 
      dplyr::filter(condition == cond)
    # now we can do the cross correlation analysis
    # we will do this for each axis
    for (axis in c("x", "y", "z")) {
      results <- ccf(
        x = cond_data[cond_data$subject == "A", axis],
        y = cond_data[cond_data$subject == "B", axis],
        na.action = na.omit,
        plot = FALSE,
        lag.max = max_lag
      )
      # make a tibble with the results
      results <- tibble(
        lagv = results$lag,
        acfv = results$acf,
        marker = marker,
        condition = cond,
        axis = axis
      )
      xcor_results[[length(xcor_results) + 1]] <- results
    }
  }
}

# let's put all the acf results into a single tibble
xcor_results <- do.call(bind_rows, xcor_results)


# now we can plot the results for each lag point
xcor_results %>%
  ggplot(aes(x = lagv, y = acfv, color = axis)) +
  geom_point() +
  theme_minimal() +
  facet_wrap(c(~condition, ~marker)) +
  labs(
    x = "Lag",
    y = "Autocorrelation",
    title = "Autocorrelation by lag"
  )

# let's also get the min and max autocorrelation for each condition and marker
xcor_results %>%
  group_by(condition, marker, axis) %>%
  summarise(
    min = min(acfv),
    max = max(acfv),
    lag_min = lagv[which.min(acfv)],
    lag_max = lagv[which.max(acfv)]
  )

```

```{r 'Windowed cross correlation analysis'}
# windowed version of the cross correlation analysis

# Mess around with the values below, see what happens! :)

# set the window size in samples
window_size <- 600 # 2 seconds
max_lag <- 150 # 0.5 seconds
step_size <- 300 # 1 second
axes_of_interest = c("x", "y")

# define an empty list to store the results
xcor_results <- list()
conds <- unique(selected_traj_data$condition)
for (marker in markers_of_interest) {
  # loop conditions
  for (cond in conds) {
    # get the data for the condition
    cond_data <- selected_traj_data %>% 
      dplyr::filter(
        marker == marker &
        condition == cond)
    # loop axes
    for (axis in axes_of_interest) {
      # get the data for the axis
      axis_data <- cond_data %>% 
        ungroup() %>%
        dplyr::select(subject, axis)
      subjA <- axis_data[axis_data$subject == "A", axis]
      subjB <- axis_data[axis_data$subject == "B", axis]
      row_count <- nrow(subjA)
      # we will do this for each window
      for (window_start in seq(1, row_count - window_size, step_size)) {
        # get the window end
        window_end <- window_start + window_size - 1
        # make sure we don't go over the end of the data
        if (window_end > row_count) {
          window_end <- row_count
        }
        # now we can do the cross correlation analysis
        results <- NULL
        tryCatch({
          results <- ccf(
            x = subjA[window_start:window_end,],
            y = subjB[window_start:window_end,],
            na.action = na.omit,
            plot = FALSE,
            lag.max = max_lag
          )
          # make a tibble with the results
          results <- tibble(
            lagv = results$lag,
            acfv = results$acf,
            marker = marker,
            condition = cond,
            axis = axis,
            window_start = window_start,
            window_end = window_end
          )
          xcor_results[[length(xcor_results) + 1]] <- results
        },
        error = function(e) {
          warning(paste(
            "Error doing cross correlation analysis, too many NAs?",
            "Condition:",
            cond,
            "Marker:",
            marker,
            "Axis:",
            axis,
            "Window start:",
            window_start,
            "Window end:",
            window_end,
            "Error:",
            e
            )
          )
          results <- NULL
        }
        )
      }
    }
  }
}

xcor_results <- do.call(bind_rows, xcor_results)

# plot a heatmap for each condition, marker, axis
xcor_results %>%
  ggplot(aes(x = lagv, y = window_start, fill = acfv)) +
  geom_tile() +
  scale_fill_distiller(palette = "Spectral") +
  theme_minimal() +
  facet_wrap(c(~condition, ~marker, ~axis)) +
  labs(
    x = "Lag",
    y = "Window start",
    title = "Autocorrelation by lag and window start"
  )

```

```{r 'Dynamic time warping for a single marker'}
# we want to do dynamic time warping for a single marker
# we will do this for each condition
# To do this, it's just a matter of getting the time series for each subject and condition

# pick a single marker to do the analysis on
sel_marker <- markers_of_interest[1]
conds <- unique(selected_traj_data$condition)
# define the window size (in samples)
# this is how far ahead and behind we can look for a match
# you can play around with these values, but keep in mind
# DTW is very processor heavy and can take some time

axes_of_interest = c("x", "y")
original_sample_rate <- 300

decimate_factor <- 6 # meaning our new sample rate is 50 Hz
window_size_samples <- 50 # meaning our window size is 1 second

# this is a disgusting resampling method
resampled_traj_data <- selected_traj_data %>% 
  group_by(condition, subject, marker) %>%
  dplyr::filter(
    index %% decimate_factor == 0
  ) %>%
  ungroup()

# finally, we may benefit from standardizing the data
# if we do this by condition, subject and marker
# we can compare relative movements between subjects
# for specific markers, but we loose the distance between them
# if we use condition and subject, we keep the relative marker distance
# within a subject, but we loose the relative distance between subjects
resampled_traj_data <- resampled_traj_data %>% 
  group_by(condition, subject, marker) %>%
  mutate_at(
    vars(x, y, z),
    ~ scale(.)
  ) %>%
  ungroup()

results <- list()
for (cond in conds) {
  for (axis in axes_of_interest) {
    # get the data for the condition
    cond_data <- resampled_traj_data %>% 
      dplyr::filter(condition == cond & marker == sel_marker)
    # now we can do the dynamic time warping for the marker between subjects
    message(paste("
      Doing dynamic time warping for condition:",
      cond,
      "Marker:",
      sel_marker,
      "Axis:",
      axis))
    message("This may take a while...")
    result <- NULL
    tryCatch({
      # Do the actual DTW analysis
      result <- dtw(
          x = cond_data[cond_data$subject == "A", axis],
          y = cond_data[cond_data$subject == "B", axis],
          window.type = "sakoechiba",
          window.size = window_size_samples,
          keep = TRUE
        )
      },
      error = function(e) {
        warning(paste(
          "Error doing DTW, skipping...maybe try standardizing?",
          "Condition:",
          cond,
          "Marker:",
          sel_marker,
          "Axis:",
          axis,
          "Length of A:",
          length(cond_data[cond_data$subject == "A", axis]),
          "Length of B:",
          length(cond_data[cond_data$subject == "B", axis]),
          "Error:",
          e
          )
        )
        result <- NULL
      }
    )
    if (is.null(result)) {
      message("Skipping...check warning messages at end of output")
      next
    }
    results[[length(results) + 1]] <- list(
      condition = cond,
      marker = sel_marker,
      axis = axis,
      normalizedDistance = result$normalizedDistance,
      distance = result$distance
    )
      

    # plot the results
    message("Plotting results...")
    message("Generating alignment plot...")
    png(
      paste0(
        "./results/DTW_alignment_plot_",
        cond,
        "_",
        sel_marker,
        "_",
        axis,
        ".png"
      )
    )
    plot(result, type = "alignment")
    dev.off()

    message("Generating twoway plot...")
    png(
      paste0(
        "./results/DTW_twoway_plot_",
        cond,
        "_",
        sel_marker,
        "_",
        axis,
        ".png"
      )
    )
    plot(result, type = "twoway")
    dev.off()
    
    message("Generating threeway plot...")
    plot(result, type = "threeway")

    dev.off()
    message("Generating density plot, burning computer...")
    png(
      paste0(
        "./results/DTW_density_plot_",
        cond,
        "_",
        sel_marker,
        "_",
        axis,
        ".png"
      )
    )
    plot(result, type = "density")
    dev.off()
    # save the density plot

  }
}


# print the resulting normalized distances
results

```

```{r 'Transfer entropy analysis'}
# we want to do a transfer entropy analysis
sel_marker <- markers_of_interest[1]
conds <- unique(selected_traj_data$condition)
axes_of_interest = c("x", "y")



results <- list()
plan(multisession)
for (cond in conds) {
  for (axis in axes_of_interest) {
    # get the data for the condition
    cond_data <- selected_traj_data %>% 
      dplyr::filter(condition == cond & marker == sel_marker)
    # now we can do the transfer entropy analysis for the marker between subjects
    message(paste("
      Doing transfer entropy analysis for condition:",
      cond,
      "Marker:",
      sel_marker,
      "Axis:",
      axis))
    message("This may take a while...")
    result <- NULL
    tryCatch({
        result <- transfer_entropy(
          x = cond_data[cond_data$subject == "A", axis],
          y = cond_data[cond_data$subject == "B", axis]
        )
      },
      error = function(e) {
        warning(paste(
          "Error doing transfer entropy analysis, skipping...maybe try standardizing?",
          "Condition:",
          cond,
          "Marker:",
          sel_marker,
          "Axis:",
          axis,
          "Length of A:",
          length(cond_data[cond_data$subject == "A", axis]),
          "Length of B:",
          length(cond_data[cond_data$subject == "B", axis]),
          "Error:",
          e
          )
        )
        result <- NULL
      }
    )
    if (is.null(result)) {
      message("Skipping...check warning messages at end of output")
      next
    }
    results[[length(results) + 1]] <- list(
      condition = cond,
      marker = sel_marker,
      axis = axis,
      te = result
    )
  }
}
plan(sequential)
# print the resulting transfer entropy values
results

```


